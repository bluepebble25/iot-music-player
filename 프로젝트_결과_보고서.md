# 2학기 무선네트워크 프로젝트 
#### <strong> 프로젝트 주제 : 표정인식 자동 뮤직 플레이어 & 휴 전구 </strong> 
###### 팀원 : 이현지, 조은지, 김정현, 홍유정 </br></br></br>

<ol>
    ● 목차 
 <ul>
   1. 프로젝트 목표 </ul><ul> 
   2. 개발 내용 </ul><ul> 
   3. 구현 방법 </ul><ul> 
    4. 코드 분석 
    <ul> 4-1. pip 설명 </ul>
    <ul> 4-2. 표정 인식 코드 분석</ul>
    <ul> 4-3. 크롤링 코드 분석 </ul>
    </ul><ul> 
   5. 프로젝트 결과</ul> </br>

<hr>
<strong>1. 프로젝트 목표 </strong></br></br>
<ul>
라즈베리 파이와 통신하는 방법을 터득하고  </br>
크롤링 기능을 활용하여 웹에서 원하는 데이터를 가지고 활용하며 </br>
데이터 값을 가지고 필립스 휴 전구에 적용시켜 프로젝트 기간안에 프로젝트에 필요한 기능들을 구현하는 능력을 키우고자 함 </ul> </br> </br> </br>

<strong>2. 개발 내용 </strong></br>
<ul>
캠을 통해 기쁨, 슬픔, 화남 등 사람의 표정을 인식한다</br>
<strong>크롤링 기능</strong>을 사용해 VIBE 웹사이트에 접속한다 </br>
로그인 후 음악 보관함에서 자신의 플레이리스트(Happy, Sad, Agry)에서 인식한 표정 중 </br> 예측값이 가장 높은 값과 같은 플레이리스트에서 노래를 랜덤 재생한다 </br>
현재 재생중인 노래의 가수 앨범사진에서 색상을 추출하여 필립스 휴 전구로 색상을 표현하고자 함 </ul> </br> </br> </br>

<strong>3. 구현 방법 </strong></br>
<ol> ● 필요한 부품  <ul>-라즈베리파이, 휴 전구, 소켓, 볼트 변환기</ul> </ol></br>
<ol> ● 필요한 기능  <ul>-캠으로 표정을 인식하는 기능 </ul><ul>
               -웹 사이트 크롤링 기능</ul><ul>
               -웹 사이트 로그인 기능 </ul><ul>
               -앨범 사진 색상 추출하는 기능 </ul><ul>
               -추출한 색을 휴 전구로 표현하는 기능 </ol><ul> </ul></br>
<ol> ● 구현 설명 
<ul>1) 캠을 통해 기쁨, 슬픔, 화남 등 사람의 표정을 인식한다</br>
2) 크롬 드라이버로 VIBE 웹사이트를 불러온다 </br>
3) 크롤링을 사용하여 자동 로그인 후 음악 보관함에서 자신의 플레이리스트(Happy, Sad, Agry)와 1)에서 인식한 표정 중 </br> 예측값이 가장 높은 값과 같은 플레이리스트를 랜덤 재생한다 </br>
4) 현재 재생중인 노래의 앨범사진에서 색상을 추출하여 필립스 휴 전구로 색상을 표현하고자 함 </ul></ol> </br> </br> </br>

<strong>4. 코드 분석 </strong></br>
<ol> 4-1. pip 설명 </br></br>
        <ol> <ul> -beautifulsoup4 : HTML정보로 부터 원하는 데이터를 가져오기 쉽게, 비슷한 분류의 데이터별로 나누어주는(parsing) 파이썬 라이브러리 </ul></br>
             <ul> -selenium : 브라우저 동작을 제어해서 마치 사람이 이용하는 것 같이 웹페이지를 요청하고 응답을 받아올 수 있다</ul></br>
             <ul> -lxml : 브라우저에서 가져온 html 코드를 가지고 parsing하는 데에 사용 </ul></br>
             <ul> -numpy : 다차원 배열을 쉽게 처리하고 효율적으로 사용할 수 있도록 지원하는 파이썬 패키지 </ul></br>
             <ul> -opencv-python : 다양한 영상/동영상 처리에 사용할 수 있는 오픈소스 라이브러리 </ul></br>
             <ul> -scikit-learn : 파이썬에서 가장 유명한 머신러닝 라이브러리중 하나로, 분류, 회귀, 군집화, 의사결정 트리 등의 다양한 머신러닝 알고리즘을 적용할 수 있는 함수들을 제공한다 </ul></br>
            <ul> -pyperclip : 간단하게 파이썬으로 클립보드에 텍스트를 '복사'하고, 저장한 텍스트를 '붙여넣기'할 수 있다.</ul> </ol></ol></br>
<hr>

<ol> 4-2. 표정 인식 코드 분석 </br></br> 
        
<img width="630" alt="emotionCode1" src="https://user-images.githubusercontent.com/80368992/144703661-c91dd665-8367-4ee4-a853-297b53f375e2.PNG"></br></br>
     
<ul> 1) CascadeClassifier로 얼굴인식 학습결과 파일을 불러온다</ul></br>
<ul>    load_model로 h5 또는 hdf5(표정인식 학습결과 파일)로 저장된 모델 구조를 불러온다</ul></br>
<ul>    화남,  역겨운, 두려운,  행복, 슬픈, 놀란, 무표정 값이 들어간 EMOTIONS 배열생성 </ul></br></br>
        
<ul> 2) camera = cv2.VideoCapture(0)으로 웹 캠을 이용하여 비디오 재생</ul></br>
<ul>      while문으로 계속하여 재생되는 비디오를 한 프레임 씩 읽어들인다</ul></br>
<ul>      ret, frame = camera.read() 정상적인 값을 받으면, ret가 True이고, read 함수로 비디오를 한 프레임씩 읽어들임</ul> </br></br>
        
<ul> 3) 배경과 현재 입력 프레임(frame)과의 차영상을 이용하여 객체를 검출해야 하기 때문에</ul></br>
<ul>    cvtColor(frame, cv2.COLOR_BGR2GRAY)로 이미지(배경)를 회색조로 변경한다</ul></br>
<ul>    face_detection.detectMultiScale로 얼굴을 먼저 검출한다 (아직 표정을 예측하는게 아님)</ul> </br>
        <ol><ul>* gray = 대상 이미지</ul></br>
        <ul>* scaleFactor=1.1 = 이미지 크기</ul></br>
        <ul>* minNeighbors=5 = 얼굴 검출 후보들의 개수 </ul></br>
        <ul>* minSize=(30,30) = 가능한 최소 객체(얼굴) 사이즈 </ul>
        </ol> </br></br>
       
<ul> 4) 감정 예측 데이터 값을 나타낼 검정색 캔버스 생성해준다 </ul></br>
<ul>    zeros()는 numpy의 배열을 생성해주는 함수</ul></br></br>

<ul> 5) 만약에 3)에서 얼굴이 검출된 값이 들어있는 faces가 0이상일 때 즉, 이미지를 검출했을 때 </ul></br>
<ul>    검출한 이미지를 face에 정렬하여 넣어준다 </ul></br>
<ul>    numpy 배열에  expand_dims()함수를 사용해 검출된 roi(이미지 배열)를 차원에 추가하고 다시 roi에 넣어준다 </ul></br></br>

<ul> 6) 이제 표정 인식학습 결과 파일로 이미지(roi)에서 감정을 예측하고 결과를 preds에 넣는다 
        (예측한 값이 여러개 일 수 있음 Happy또는 Sad 등 여러 값이 나타날 수 있음 ) </br>
        <ul> ※ predict() 함수는 주어진 새로운 변수(X)에 대한 예측을 수행한 결과를 예측값으로 출력</ul></ul></br>
<ul>    preds에서 가장 큰 값 즉, 예측값이 가장 큰 값을 가져와 emotion_probability에 넣고 </ul>
<ul>    preds배열에서 가장 높은 값을 가진 값의 인덱스를 가져오고 EMOTIONS배열에서 그 인덱스 값에 해당하는 값을 가지고 와 label변수에 넣는다</ul></br></br>

<ul> 7) 프레임(얼굴 영상 창)에 예측한 표정 라벨을 출력
         <ul>문자 좌표(fX, fY - 10)를 글자의 우측 하단을 시작점으로 하여 주어진 텍스트(label)를 출력</ul></br>
         <ul> ※ 도형 그리기는 동영상이나 이미지에서 Match가 되는 영역을 찾은 후에 사용자가 인식하기 쉽게 표시하는 목적으로 사용</ul></ul> </br></br></br>

<img width="721" alt="emotionCode2" src="https://user-images.githubusercontent.com/80368992/144703667-3a0e144c-854d-42a0-adbc-908276e919c2.PNG"> </br></br>

<ol> 8) 캔버스(표정 검출 데이터 창)에 라벨링한다
<ul>  zip()함수로 EMOTIONS배열과 preds의 값을 순서 쌍으로 묶음 ex)[(happy(EMOTIONS배열), 예측 값(preds))]</ul></br>
<ul>  enumerate()함수로 순서쌍을 열거한다.</ul></br>
<ul>  for문으로 순서쌍 데이터를  emotion = EMOTION, preds = prob로 꺼내옴 </ul></br>
<ul>  text변수에 "happy : 35.05%"식으로 emotion과 예측값*100을 해주어 넣어준다 </ul></br>
<ul>  표정 검출 데이터 창인 캔버스에 text를 넣어주고 , 각각 표정을 예측한 값만큼 사각형으로 시각화 해준다. </ul></br>
<ul>  imshow()함수로 프레임과 캔버스창에 텍스트를 지정 </ul></br>
<ul>  사용자가 키보드 "q"를 누르면 그냥 프로그램이 break문으로 빠져나오고 </ul></br>
<ul>  특정 표정 예측값이 클 때 "c"를 누르면 그 표정 값을 가져오고 표정 인식은 break문으로 빠져나온다  </ul></br> 
<ul>  추후에 표정값과 같은 플레이리스트를 불러오기 위해 maxEmotion = EMOTIONS[index]를 해준다 </ul></ol>
</ol></br></br>

<ol><img width="786" alt="crawlingCode1" src="https://user-images.githubusercontent.com/80368992/144708639-df4c5356-c60b-45f5-9334-9d95126a0311.PNG"></br></br>
<ul>1) chromedriver.exe를 로컬에서 불러오고 get()함수로 vibe사이트를 띄운다.</ul>
<ul>find_elements_by_xpath() 함수를 사용하여 vibe사이트를 띄울 때 나타나는 모달창을 꺼준다</ul></br>
    <ul>※ 웹사이트에서 xpath가져오는 방법 :  f12를 눌러 개발자 도구를 열어 Ctrl+Shift+c로 가져올 요소를 선택해준다
    선택후 우클릭으로 Xpath를 복사해준다 </ul></ul></br>
<ul>2) 동일한 방법으로 로그인 박스를 클릭하여 로그인창으로 이동하도록 한다</ul></br>
<ul>    try-except문으로 로그인 돼 있을 경우는"***님 안녕하세요"를 출력해주고 아닌경우 login함수를 호출한다. </ul></br>
<ul>    사용자가 입력한 아이디를 id변수에 넣고 copy()함수로 클립보드에 id를 복사해준다</ul></br>
<ul>    find_element_by_id로 "id"라는 id를 갖은 요소를 가져오고 send_keys()함수로 id 값을 넣어준다 </ul></br>
<ul>    패스워드도 동일한 방법으로 해주고 로그인 버튼을 누른다 </ul></br></br>

<ul>3) 만약 로그인에 실패할 경우 -> 로그인 실패시 메세지가 생기기 때문에 그에 관련된 박스를 찾아온다 </ul></br> 
<ul>   login_error.text으로 로그인 실패 원인을 알려준다 (아이디나 패스워드 오류) </ul></br>
<ul>   clear()함수로 로그인창에 있던 id를 지워준다 </ul></br>
<ul>   로그인 성공 시 -> 로그인 성공시 알려주고 아이디와 패스워드 등록여부를 거절한다 </ul>
</ol></br></br>

<ol><img width="899" alt="crawlingCode2" src="https://user-images.githubusercontent.com/80368992/144708640-ec9a02dd-8a55-4228-b64e-f49a00fee2ad.PNG"></br></br>
<ul>4) 1)번과 같은 방식으로 driver.find_element_by_xpath을 사용하여 보관함으로 이동하고 플레이리스트로 이동한다</ul></br>
<ul>   플레이리스트에서 이름을 갖고 와야 하는데 li:nth-child()이런식으로 돼 있다  </ul></br>
<ul>   :nth-child()을 제거하여 자식 요소들을 모두 갖고온다 driver.find_elements_by_css_selector는 list형식으로 값이 반환이 된다</ul></br>
<ul>   이 플레이리스에는 맨 뒤는 필요없는 리스트가 있기에 이것을 제거하기 위해 plist 배열을 따로 만들어 준다 </ul></br>
<ul>   for문으로 plist_names에 있는 값을 plist_name으로 꺼내오고 plist 배열에 플레이리스트 값들을 text형식으로 append해준다</ul></br>
<ul>   pop()함수로 마지막 기본 플레이리스트 이름 제거한다 </ul></br>
<ul>   if-else문으로 plist에서 위에 8)에서 추출한 표정 값이 있는지 확인한다 만약 리스트에 없으면 알려준다</ul></br>
<ul>   for문으로 돌리며  enumerate로 플레이리스트들의 인덱스번호와 값을 idx, val로 가져온다
        <ul> ※ enumerate 함수를 사용하면 인덱스 번호와 컬렉션의 원소를 튜플 형태로 반환</ul></ul></br>
<ul>   만약 플레이리스트의 인덱스 값이 추출한 표정과 같다면 플레이리스트의 이름과 인덱스 번호를 출력해준다</ul></br>
<ul>   그리고 plist_names[idx].click()으로 인덱스 번호에 맞는 플레이리스트를 클릭하도록 한다</ul></br>
<ul>   마지막으로 랜덤 재생 버튼을 눌러 노래가 자동으로 나오도록 해준다</ul></ol>

<hr>
<ol><strong>5. 프로젝트 결과 </strong></br></br>
<ul><img width="435" alt="실행결과1" src="https://user-images.githubusercontent.com/80368992/144711901-6dc7505a-d133-4655-a260-6bd381a0b645.PNG"></ul></br> 
<ul><img width="743" alt="실행결과2" src="https://user-images.githubusercontent.com/80368992/144711904-30907c86-ea06-49bb-bd2b-f5f9f7d0fa16.PNG"></ul></br> 
<ul><img width="594" alt="실행결과3" src="https://user-images.githubusercontent.com/80368992/144711905-942cdbd8-3316-4d8f-a1ce-09d465190e47.PNG"></ul></br></ol>

</br></br>
